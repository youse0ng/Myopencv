{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'화상데이터_어노테이션데이터_파일경로 생성'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path as os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "'''화상데이터_어노테이션데이터_파일경로 생성'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(rootpath:str):\n",
    "    '''\n",
    "    데이터 경로를 저장한 리스트 작성\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    rootpath: str\n",
    "        데이터 폴더 경로\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    ret: train_img_list, train_anno_list, val_img_list, val_anno_list\n",
    "        데이터 경로를 저장한 리스트\n",
    "    '''\n",
    "\n",
    "    # 화상 파일과 어노테이션 파일의 경로 템플릿 작성\n",
    "    imgpath_template=os.join(rootpath + 'JPEGImages', '%s.jpg')\n",
    "    annopath_template=os.join(rootpath + 'Annotations', '%s.xml')\n",
    "\n",
    "    # 훈련 및 검증 파일 ID(파일 이름) 취득\n",
    "    train_id_names=os.join(rootpath + 'ImageSets/Main/train.txt')\n",
    "    val_id_names=os.join(rootpath + 'ImageSets/Main/val.txt')\n",
    "\n",
    "    # 훈련 데이터의 화상 파일과 어노테이션 파일의 경로 리스트 작성\n",
    "    train_img_list = list()\n",
    "    train_anno_list = list()\n",
    "\n",
    "    for line in open(train_id_names):\n",
    "        file_id = line.strip() # 공백과 줄 바꿈 제거\n",
    "        img_path = (imgpath_template % file_id) # 화상 경로\n",
    "        anno_path = (annopath_template % file_id) # 어노테이션 경로\n",
    "        train_img_list.append(img_path) # 리스트에 화상경로 추가\n",
    "        train_anno_list.append(anno_path) # 리스트에 어노테이션 경로 추가\\\n",
    "\n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "    \n",
    "    for line in open(val_id_names):\n",
    "        file_id = line.strip()\n",
    "        img_path= (imgpath_template % file_id)\n",
    "        anno_path= (annopath_template % file_id)\n",
    "        val_img_list.append(img_path)\n",
    "        val_anno_list.append(anno_path)\n",
    "\n",
    "    return train_img_list, train_anno_list, val_img_list, val_anno_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hyssk/Myopencv/DeepLearningVision/SSD/data/JPEGImages\\2008_000008.jpg\n"
     ]
    }
   ],
   "source": [
    "rootpath='C:/Users/hyssk/Myopencv/DeepLearningVision/SSD/data/'\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list=make_datapath_list(rootpath=rootpath)\n",
    "print(train_img_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''XML 형식의 어노테이션 데이터를 리스트로 변환하기'''\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anno_xml2list(object):\n",
    "    '''\n",
    "    한 화상의 XML 형식 어노테이션 데이터를 화상 크기로 규격화하여 리스트 형식으로 변환\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes: 리스트\n",
    "        VOC의 클래스명을 저장한 리스트\n",
    "    '''\n",
    "\n",
    "    def __init__(self, classes):\n",
    "        self.classes=classes\n",
    "    \n",
    "    def __call__(self,xml_path,width,height):\n",
    "        '''\n",
    "        한 화상의 XML 형식 어노테이션 데이터를 화상 크기로 규격화하여 리스트 형식으로 변환\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xml_path: str\n",
    "            xml 파일 경로\n",
    "        width: int\n",
    "            대상 화상 폭\n",
    "        height: int\n",
    "            대상 화상 높이\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        ret : [[xmin,ymin,xmax,ymax,label_ind],...]\n",
    "            물체의 어노테이션 데이터를 저장한 리스트. 화상에 존재하는 물체 수만큼의 요소를 가진다.\n",
    "        '''\n",
    "        # 화상 내 모든 물체의 어노테이션을 이 리스트에 저장\n",
    "        ret=[]\n",
    "\n",
    "        # xml 파일 로드\n",
    "        xml = ET.parse(xml_path).getroot()\n",
    "        # 화상 내 물체(object) 수만큼 반복\n",
    "        for obj in xml.iter('object'):\n",
    "            # 어노테이션에서 검지가 difficult로 설정된 것은 제외\n",
    "            difficult = int(obj.find('difficult').text)\n",
    "            if difficult == 1:\n",
    "                continue\n",
    "\n",
    "            # 한 물체의 어노테이션을 저장하는 리스트\n",
    "            bndbox=[]\n",
    "            name = obj.find('name').text.lower().strip()\n",
    "            bbox = obj.find('bndbox') # 바운딩 박스 정보\n",
    "\n",
    "            # 어노테이션의 xmin, ymin, xmax, ymax를 취득하고 0~1으로 규격화\n",
    "            pts = ['xmin','ymin','xmax','ymax']\n",
    "\n",
    "            for pt in (pts):\n",
    "                # VOC는 원점이 (1,1)이므로 1을 빼서 (0,0) 으로 한다.\n",
    "                cur_pixel=int(bbox.find(pt).text) - 1\n",
    "                # 폭, 높이로 규격화\n",
    "                if pt == 'xmin' or pt == 'xmax':\n",
    "                    cur_pixel/=width\n",
    "                \n",
    "                else:  # y 방향의 경우 높이로 나눈다.\n",
    "                    cur_pixel /= height\n",
    "                bndbox.append(cur_pixel)\n",
    "\n",
    "            # 어노테이션의 클래스명 index를 취득하여 추가\n",
    "            label_idx = self.classes.index(name)\n",
    "            bndbox.append(label_idx)\n",
    "\n",
    "            ret+=[bndbox]\n",
    "        return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/hyssk/Myopencv/DeepLearningVision/SSD/data/Annotations\\2008_000008.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.104     ,  0.19457014,  0.94      ,  0.9479638 , 12.        ],\n",
       "       [ 0.314     ,  0.09728507,  0.576     ,  0.37556561, 14.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_classes=['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow',\n",
    "             'diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa',\n",
    "             'train','tvmonitor']\n",
    "\n",
    "transform_anno=Anno_xml2list(voc_classes)\n",
    "image_file_path=train_img_list[0]\n",
    "img=cv.imread(image_file_path)\n",
    "height,width,channels=img.shape # [높이][폭][색BGR(채널)]\n",
    "print(train_anno_list[0]) # 화상 크기 취득\n",
    "transform_anno(train_anno_list[0],width,height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_augumentation import Compose, ConvertFromInts, ToAbsoluteCoords, PhotometricDistort,Expand,RandomSampleCrop, RandomMirror,ToPercentCoords,Resize,SubtractMeans\n",
    "'''util 폴더는 github.com/YutaroOgawa 에서 가져왔습니다.\n",
    "    입력 영상의 전처리 클래스\n",
    "'''\n",
    "\n",
    "class DataTransform():\n",
    "    \"\"\"\n",
    "    화상과 어노테이션의 전처리 클래스, 훈련과 추론에서 다르게 작동\n",
    "    화상 크기를 300*300으로 해야한다.\n",
    "    학습 시 데이터 데이터 확장을 수행한다.\n",
    "\n",
    "    Attributes \n",
    "    ----------\n",
    "    input_size: int\n",
    "        리사이즈 대상 화상의 크기\n",
    "    color_mean: (B,G,R)\n",
    "        각 색상 채널의 평균값\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,input_size,color_mean):\n",
    "        self.data_transform = {\n",
    "            'train':Compose([\n",
    "                ConvertFromInts(), # int를 Float32로 변환\n",
    "                ToAbsoluteCoords(), # 어노테이션 데이터의 규격화 반환\n",
    "                PhotometricDistort(), # 화상의 색조 등 임의로 변환\n",
    "                Expand(color_mean),# 화상의 캔버스 확대\n",
    "                RandomSampleCrop(), # 화상 내의 특정 부분 무작위 추출\n",
    "                RandomMirror(), # 화상 반전\n",
    "                ToPercentCoords(), # 어노테이션 데이터를 0~1로 규격화\n",
    "                Resize(input_size), # 화상 크기를 input_size * input_size로 변형\n",
    "                SubtractMeans(color_mean) # BGR 색상의 평균값 빼기\n",
    "            ]),\n",
    "            'val': Compose([\n",
    "                ConvertFromInts(), #int를 float로 변환\n",
    "                Resize(input_size), # 화상 크기를 input_size * input_size로 변형\n",
    "                SubtractMeans(color_mean) # BGR 색상의 평균값 빼기\n",
    "            ])\n",
    "        }\n",
    "    def __call__(self,img,phase,boxes,labels): # 클래스 객체를 부르면 return 함\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase: 'train' or 'val'\n",
    "            전처리 모드 지정\n",
    "        '''\n",
    "        return self.data_transform[phase](img,boxes,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 화상 읽기\n",
    "image_file_path=train_img_list[0]\n",
    "img=cv.imread(image_file_path) # [높이][폭][색BGR]\n",
    "height,width,channels=img.shape # 화상 크기 취득\n",
    "print(f'width: {width}')\n",
    "print(f'height: {height}')\n",
    "# 2. 어노테이션을 리스트로 \n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "anno_list = transform_anno(train_anno_list[0],width,height) \n",
    "\n",
    "# 3. 원본 표시\n",
    "plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB))\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "\n",
    "# 4. 전처리 클래스 작성\n",
    "color_mean = (104,117,123) # (BGR) 색상의 평균값\n",
    "input_size = 300 # 화상의 input_size를 300*300\n",
    "transform = DataTransform(input_size=input_size, color_mean=color_mean) # 클래스 객체 생성\n",
    "\n",
    "# 5. Train 화상 표시\n",
    "phase = 'train'\n",
    "img_transformed, boxes, labels = transform(img, phase, anno_list[:, :4], anno_list[:,4])\n",
    "\n",
    "cv.imshow('image_transformed',cv.cvtColor(img_transformed,cv.COLOR_BGR2RGB))\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
